{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf8f3f30",
   "metadata": {},
   "source": [
    "\n",
    "# CheckPoint 4 — COP30 (Belém) — Comparação (BF vs D&C vs DP)\n",
    "\n",
    "Preencha a seção de **Composição do Grupo** abaixo e execute as células em ordem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56590c5",
   "metadata": {},
   "source": [
    "\n",
    "## Composição do Grupo\n",
    "- Guilherme Lunghini Teixeira – RM 555892\n",
    "- Luan Ramos Garcia de Souza – RM 558537\n",
    "- Marchel Augusto Ribeiro de Matos – RM 99856\n",
    "- Matheus Ricciotti – RM 556930\n",
    "- Matheus Bortolotto – RM 555189\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2f12f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mknapsack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_projects, knapsack_bruteforce, knapsack_meet_in_the_middle, knapsack_dp, QUALITY_REGISTRY \u001b[38;5;28;01mas\u001b[39;00m KNAPSACK_QREG\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmaxsubarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_days, maxsub_bruteforce, maxsub_divide_conquer, kadane, QUALITY_REGISTRY \u001b[38;5;28;01mas\u001b[39;00m MAXSUB_QREG\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\n",
    "import time, math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from knapsack import gen_projects, knapsack_bruteforce, knapsack_meet_in_the_middle, knapsack_dp, QUALITY_REGISTRY as KNAPSACK_QREG\n",
    "from maxsubarray import gen_days, maxsub_bruteforce, maxsub_divide_conquer, kadane, QUALITY_REGISTRY as MAXSUB_QREG\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc5947",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio 1 — Mochila 0/1 (Seleção de Projetos)\n",
    "Rodamos as três abordagens e validamos a correção em uma instância pequena; em seguida, benchmark no intervalo **(10..25)** como no enunciado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checagem de corretude rápida (instância pequena)\n",
    "projects = [(3,25), (4,35), (7,70), (8,80)]\n",
    "budget = 10\n",
    "bf_b, _ = knapsack_bruteforce(projects, budget)\n",
    "mi_b, _ = knapsack_meet_in_the_middle(projects, budget)\n",
    "dp_b, _ = knapsack_dp(projects, budget)\n",
    "assert bf_b == mi_b == dp_b, \"Soluções diferentes no Desafio 1!\"\n",
    "print(\"OK — correção verificada (Desafio 1).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ecc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Benchmark do Desafio 1 — n = 10..25 (aderente ao enunciado)\n",
    "def benchmark_knapsack_assignment(ns=(10,12,14,16,18,20,22,24,25), repeats=1, budget=60):\n",
    "    times_bf, times_mi, times_dp = [], [], []\n",
    "    for n in ns:\n",
    "        projects = gen_projects(n, seed=2025 + n)\n",
    "        tb, tm, td = [], [], []\n",
    "\n",
    "        # Warm-up fora da cronometragem\n",
    "        try:\n",
    "            if n <= 22:\n",
    "                _ = knapsack_bruteforce(projects, budget)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        _ = knapsack_meet_in_the_middle(projects, budget)\n",
    "        _ = knapsack_dp(projects, budget)\n",
    "\n",
    "        for _ in range(repeats):\n",
    "            # Brute Force (apenas até n<=22)\n",
    "            if n <= 22:\n",
    "                try:\n",
    "                    t0 = time.perf_counter()\n",
    "                    knapsack_bruteforce(projects, budget)\n",
    "                    tb.append(time.perf_counter() - t0)\n",
    "                except ValueError:\n",
    "                    tb.append(float('nan'))\n",
    "            else:\n",
    "                tb.append(float('nan'))\n",
    "\n",
    "            # MiTM\n",
    "            t0 = time.perf_counter()\n",
    "            knapsack_meet_in_the_middle(projects, budget)\n",
    "            tm.append(time.perf_counter() - t0)\n",
    "\n",
    "            # DP\n",
    "            t0 = time.perf_counter()\n",
    "            knapsack_dp(projects, budget)\n",
    "            td.append(time.perf_counter() - t0)\n",
    "\n",
    "        def mean_ms(vs):\n",
    "            vals = [v for v in vs if not (isinstance(v,float) and math.isnan(v))]\n",
    "            return (sum(vals)/len(vals)*1000) if vals else float('nan')\n",
    "\n",
    "        times_bf.append(mean_ms(tb))\n",
    "        times_mi.append(mean_ms(tm))\n",
    "        times_dp.append(mean_ms(td))\n",
    "    return ns, times_bf, times_mi, times_dp\n",
    "\n",
    "ns, tbf, tmi, tdp = benchmark_knapsack_assignment()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ns, tbf, marker=\"o\", label=\"Brute Force (se aplicável)\")\n",
    "plt.plot(ns, tmi, marker=\"o\", label=\"Meet-in-the-Middle\")\n",
    "plt.plot(ns, tdp, marker=\"o\", label=\"DP bottom-up\")\n",
    "plt.xlabel(\"n (projetos)\")\n",
    "plt.ylabel(\"Tempo (ms)\")\n",
    "plt.title(\"Desafio 1 — Desempenho (n = 10..25)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e1cc4",
   "metadata": {},
   "source": [
    "\n",
    "## Desafio 2 — Máxima Soma Contígua (Janela de Qualidade do Ar)\n",
    "Validamos a correção e rodamos o benchmark em **n = 200, 400, 800, 1200, 1600** como no enunciado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3193480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checagem de corretude (instância pequena)\n",
    "arr = [3, -2, 5, -1, -4, 6, -3]\n",
    "bf_v, _, _ = maxsub_bruteforce(arr)\n",
    "dc_v, _, _ = maxsub_divide_conquer(arr)\n",
    "kd_v, _, _ = kadane(arr)\n",
    "assert bf_v == dc_v == kd_v, \"Soluções diferentes no Desafio 2!\"\n",
    "print(\"OK — correção verificada (Desafio 2).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250894cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Benchmark do Desafio 2 — ns exigidos\n",
    "def benchmark_maxsub_assignment(ns=(200,400,800,1200,1600), repeats=1):\n",
    "    t_bf, t_dc, t_kd = [], [], []\n",
    "    for n in ns:\n",
    "        arr = gen_days(n, seed=3000 + n)\n",
    "        tb, td, tk = [], [], []\n",
    "\n",
    "        # Warm-up\n",
    "        try:\n",
    "            if n <= 600:\n",
    "                _ = maxsub_bruteforce(arr)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        _ = maxsub_divide_conquer(arr)\n",
    "        _ = kadane(arr)\n",
    "\n",
    "        for _ in range(repeats):\n",
    "            # Brute Force até 600\n",
    "            if n <= 600:\n",
    "                try:\n",
    "                    t0 = time.perf_counter()\n",
    "                    maxsub_bruteforce(arr)\n",
    "                    tb.append(time.perf_counter() - t0)\n",
    "                except ValueError:\n",
    "                    tb.append(float('nan'))\n",
    "            else:\n",
    "                tb.append(float('nan'))\n",
    "\n",
    "            # Divide & Conquer\n",
    "            t0 = time.perf_counter()\n",
    "            maxsub_divide_conquer(arr)\n",
    "            td.append(time.perf_counter() - t0)\n",
    "\n",
    "            # Kadane\n",
    "            t0 = time.perf_counter()\n",
    "            kadane(arr)\n",
    "            tk.append(time.perf_counter() - t0)\n",
    "\n",
    "        def mean_ms(vs):\n",
    "            vals = [v for v in vs if not (isinstance(v,float) and math.isnan(v))]\n",
    "            return (sum(vals)/len(vals)*1000) if vals else float('nan')\n",
    "\n",
    "        t_bf.append(mean_ms(tb))\n",
    "        t_dc.append(mean_ms(td))\n",
    "        t_kd.append(mean_ms(tk))\n",
    "    return ns, t_bf, t_dc, t_kd\n",
    "\n",
    "ns2, tbf2, tdc2, tkd2 = benchmark_maxsub_assignment()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ns2, tbf2, marker=\"o\", label=\"Brute Force (se aplicável)\")\n",
    "plt.plot(ns2, tdc2, marker=\"o\", label=\"Divide & Conquer\")\n",
    "plt.plot(ns2, tkd2, marker=\"o\", label=\"Kadane (DP)\")\n",
    "plt.xlabel(\"n (dias)\")\n",
    "plt.ylabel(\"Tempo (ms)\")\n",
    "plt.title(\"Desafio 2 — Desempenho (200..1600)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761c420c",
   "metadata": {},
   "source": [
    "\n",
    "## Explicações e Conexões\n",
    "- **Desafio 1 (Mochila):** Brute Force (baseline), Meet‑in‑the‑Middle (2^{n/2}), DP 1D por capacidade com reconstrução.  \n",
    "- **Desafio 2 (Máx. Soma):** Brute Force (O(n²)), Divide & Conquer (O(n log n)), **Kadane (O(n))**.\n",
    "\n",
    "## Conclusões\n",
    "- DP domina quando aplicável (Mochila e Kadane), garantindo melhor escalabilidade.  \n",
    "- Limites do brute force evitam travamentos; resultados validados mutuamente com `assert`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
